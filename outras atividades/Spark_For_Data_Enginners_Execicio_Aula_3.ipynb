{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guisilcol/spark-for-data-enginners/blob/main/Spark_For_Data_Enginners_Execicio_Aula_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação de módulos e preparação do Drive\n",
        "\n"
      ],
      "metadata": {
        "id": "jNadjCWLVu_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yEBnXuyenEHP",
        "outputId": "40faf125-4ec8-4a52-d3e8-0d8c3a224298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XYqT2XObU7ZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7878b667-398e-4db4-8543-14eb09856dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bibtexparser in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from bibtexparser) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install bibtexparser\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importação de módulos e inicialização de constantes"
      ],
      "metadata": {
        "id": "G5gzxDWhZLrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pyspark.sql as spark_sql\n",
        "import pyspark.sql.functions as F\n",
        "import typing as python_types\n",
        "import pyspark.sql.types as spark_types\n",
        "import yaml\n",
        "\n",
        "CONFIG_FILEPATH = '/content/drive/MyDrive/Data/data/config.yaml'\n",
        "\n",
        "ACM_BIBTEXS_INPUT_FOLDER = '/content/drive/MyDrive/Data/data/acm/*'\n",
        "IEEE_BIBTEXS_INPUT_FOLDER = '/content/drive/MyDrive/Data/data/ieee/*'\n",
        "SCIENCE_DIRECT_BIBTEXS_INPUT_FOLDER = '/content/drive/MyDrive/Data/data/science_direct/*'\n",
        "\n",
        "JCR_FILEPATH = '/content/drive/MyDrive/Data/data/jcs_2020.csv'\n",
        "SCIMAGO_FILEPATH = '/content/drive/MyDrive/Data/data/scimagojr 2020.csv'\n",
        "\n",
        "OUTPUT_FOLDER = '/content/drive/MyDrive/Data/data/output4'\n",
        "\n",
        "\n",
        "SPARK = spark_sql.SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "43F2p48RZYcD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UDFs e Python Functions"
      ],
      "metadata": {
        "id": "4msPgogmbei4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob as get_filenames_in_folder\n",
        "from bibtexparser import load as load_bibtex_database\n",
        "from dataclasses import dataclass\n",
        "\n",
        "class BibtexHandler:\n",
        "  \n",
        "  @staticmethod\n",
        "  def parse_bibtex_folder_in_dict_list(folder_path: str):\n",
        "    filepaths = get_filenames_in_folder(folder_path)\n",
        "    files = (open(path, \"r\", encoding=\"utf-8\") for path in filepaths)  # type: ignore\n",
        "    bibtexts = (load_bibtex_database(file) for file in files)\n",
        "    bib_entries = (bib.entries for bib in bibtexts)\n",
        "    return list((item for sublist in bib_entries for item in sublist))\n",
        "\n",
        "class Operations:\n",
        "\n",
        "  @staticmethod\n",
        "  def generate_key_from_journal_name(df: spark_sql.DataFrame, journal_title_column: str, output_column: str):\n",
        "    return df.withColumn(output_column, F.regexp_replace(journal_title_column, \"&\", \"AND\"))\\\n",
        "              .withColumn(output_column, F.regexp_replace(output_column, r\"([^A-Za-z0-9]+)\", \"\"))\\\n",
        "              .withColumn(output_column, F.upper(output_column))\\\n",
        "              .withColumn(output_column, F.trim((output_column)))\n",
        "\n",
        "\n",
        "# Arquivo de configuração/filtros\n",
        "\n",
        "@dataclass\n",
        "class _Filters:\n",
        "  title: str \n",
        "  keywords: str\n",
        "  abstract: str                       \n",
        "  year: str             \n",
        "  type_publication: str        \n",
        "  doi: str            \n",
        "  jcs_value: str   \n",
        "  scimago_value: str   \n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "  export_format: str\n",
        "  filters: _Filters\n",
        "  \n",
        "  @staticmethod\n",
        "  def generate_where_clause(conf):\n",
        "    where_clause = '1 = 1 '\n",
        "    for key, value in conf.filters.items():\n",
        "      if not value == None:\n",
        "        where_clause += f'and {key} {value} ' \n",
        "\n",
        "    return where_clause\n"
      ],
      "metadata": {
        "id": "hFRG8LN2bi8N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extração de dados (Python side)"
      ],
      "metadata": {
        "id": "wYoKCq9Wav6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ACM_INPUT_DATA: python_types.List[dict] = BibtexHandler.parse_bibtex_folder_in_dict_list(ACM_BIBTEXS_INPUT_FOLDER)\n",
        "IEEE_INPUT_DATA: python_types.List[dict] = BibtexHandler.parse_bibtex_folder_in_dict_list(IEEE_BIBTEXS_INPUT_FOLDER)\n",
        "SCIENCE_DIRECT_INPUT_DATA: python_types.List[dict] = BibtexHandler.parse_bibtex_folder_in_dict_list(SCIENCE_DIRECT_BIBTEXS_INPUT_FOLDER)"
      ],
      "metadata": {
        "id": "c3p-HO8QavZW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extração e Transformação de dados\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pyv-46oXlrXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config(**yaml.load(open(CONFIG_FILEPATH), yaml.SafeLoader))\n",
        "\n",
        "########################################## Criação dos Dataframes ##########################################\n",
        "ACM_DF = SPARK.createDataFrame(ACM_INPUT_DATA).cache() # type: ignore\n",
        "IEEE_DF = SPARK.createDataFrame(IEEE_INPUT_DATA).cache() # type: ignore\n",
        "SCIENCE_DIRECT_DF = SPARK.createDataFrame(SCIENCE_DIRECT_INPUT_DATA).cache() # type: ignore\n",
        "\n",
        "JCS_DF = SPARK.read.csv(JCR_FILEPATH, sep = \";\", header = True)\n",
        "SCIMAGO_DF = SPARK.read.csv(SCIMAGO_FILEPATH, sep = \";\", header = True)"
      ],
      "metadata": {
        "id": "dPhQYJb9Vkme"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "########################################## Tratamento inicial dos bibtexs ##########################################\n",
        "acm_df = ACM_DF.select([\"author\", \"title\", \"keywords\", \"abstract\", \"year\", \"ENTRYTYPE\", \"doi\", \"issn\", \"isbn\", \"journal\"])\\\n",
        "        .withColumnRenamed(\"ENTRYTYPE\", \"type_publication\")\\\n",
        "        .withColumn(\"source\", F.lit(\"acm\"))\\\n",
        "        .withColumn(\"issn\", F.regexp_replace(\"issn\", \"-\", \"\"))\\\n",
        "        .dropDuplicates()\n",
        "\n",
        "ieee_df = IEEE_DF.select([\"author\", \"title\", \"keywords\", \"abstract\", \"year\", \"ENTRYTYPE\", \"doi\", \"issn\", \"journal\"])\\\n",
        "          .withColumnRenamed(\"ENTRYTYPE\", \"type_publication\")\\\n",
        "          .withColumn(\"source\", F.lit(\"ieee\"))\\\n",
        "          .withColumn(\"issn\", F.regexp_replace(\"issn\", \"-\", \"\"))\\\n",
        "          .withColumn(\"isbn\", F.lit(None).cast(spark_types.StringType()))\\\n",
        "          .dropDuplicates()\n",
        "\n",
        "science_direct_df = SCIENCE_DIRECT_DF.select([\"author\", \"title\", \"keywords\", \"abstract\", \"year\", \"ENTRYTYPE\", \"doi\", \"issn\", \"isbn\", \"journal\"])\\\n",
        "                    .withColumnRenamed(\"ENTRYTYPE\", \"type_publication\")\\\n",
        "                    .withColumn(\"source\", F.lit(\"science direct\"))\\\n",
        "                    .withColumn(\"issn\", F.regexp_replace(\"issn\", \"-\", \"\"))\\\n",
        "                    .dropDuplicates()\n",
        "\n",
        "########################################## Union dos bibtex ##########################################\n",
        "\n",
        "bibtex_df = acm_df.union(ieee_df).union(science_direct_df)"
      ],
      "metadata": {
        "id": "XToLlW6ylumw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################## Tratamento dos Bibtex ##########################################\n",
        "bibtex_df = bibtex_df.transform(Operations.generate_key_from_journal_name, \n",
        "                                  journal_title_column = 'journal', \n",
        "                                  output_column = 'journal_name_key')\\\n",
        "                      .withColumn('doi', F.regexp_replace('doi', 'https://doi.org/', ''))\n",
        "\n",
        "########################################## Transformação dos arquivos CSV ##########################################\n",
        "scimago_df = SCIMAGO_DF.select(['Issn', 'Title', 'SJR'])\\\n",
        "                        .withColumnRenamed('SJR', 'scimago_value')\\\n",
        "                        .withColumnRenamed('Issn', 'issn')\\\n",
        "                        .withColumnRenamed('Title', 'scimago_title')\\\n",
        "                        .transform(Operations.generate_key_from_journal_name, \n",
        "                                  journal_title_column = 'scimago_title', \n",
        "                                  output_column = 'journal_name_key')\n",
        "                        \n",
        "jcs_df = JCS_DF.select([\"Full Journal Title\", \"Journal Impact Factor\"])\\\n",
        "                .withColumnRenamed(\"Full Journal Title\", \"jcs_title\")\\\n",
        "                .withColumnRenamed(\"Journal Impact Factor\", \"jcs_value\")\\\n",
        "                .transform(Operations.generate_key_from_journal_name, \n",
        "                                  journal_title_column = 'jcs_title', \n",
        "                                  output_column = 'journal_name_key')\n",
        "\n",
        "########################################## JOIN dos arquivos CSV ##########################################\n",
        "journal_df = scimago_df.alias(\"scimago_df\")\\\n",
        "            .join(jcs_df, 'journal_name_key', 'outer')\\\n",
        "            .withColumn('title', F.coalesce(\"scimago_title\", \"jcs_title\"))\\\n",
        "            .withColumn(\"issn\", F.regexp_replace(\"issn\", \" \",\"\"))\\\n",
        "            .select(['title', 'journal_name_key', 'issn', 'scimago_value', 'jcs_value'])\\\n",
        "            .dropDuplicates([\"journal_name_key\"])\n",
        "            \n",
        "journal_df = journal_df.withColumn(\"issn\", F.when(journal_df[\"issn\"] == '-', None).otherwise(journal_df[\"issn\"]))\n",
        "\n",
        "splited_issn = F.split(journal_df[\"issn\"], \",\")\n",
        "\n",
        "journal_df = journal_df.withColumn('issn_1', splited_issn.getItem(0))\\\n",
        "                        .withColumn('issn_2', splited_issn.getItem(1))\\\n",
        "                        .withColumn('issn_3', splited_issn.getItem(3))\\\n",
        "                        .select(['title', 'journal_name_key', 'issn_1', 'issn_2', 'issn_3', 'scimago_value', 'jcs_value'])\n"
      ],
      "metadata": {
        "id": "gQasuiqj4Vu7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################## JOIN entre Bibtexs e CSV's ##########################################\n",
        "journal_df.createOrReplaceTempView(\"journal_df\")\n",
        "bibtex_df.createOrReplaceTempView(\"bibtex_df\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QoUocKmEddzk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_final = SPARK.sql(\n",
        "\"\"\"\n",
        "      SELECT DISTINCT\n",
        "            bib.author\n",
        "            ,bib.title\n",
        "            ,bib.keywords\n",
        "            ,bib.abstract\n",
        "            ,bib.year\n",
        "            ,bib.type_publication\n",
        "            ,bib.doi\n",
        "            ,bib.issn\n",
        "            ,COALESCE(bib.journal, jor.title) journal\n",
        "            ,bib.source\n",
        "            ,jor.scimago_value  \n",
        "            ,jor.jcs_value\n",
        "      FROM \n",
        "            bibtex_df bib\n",
        "            LEFT JOIN journal_df jor\n",
        "                  ON (bib.issn = jor.issn_1\n",
        "                        OR bib.issn = jor.issn_2\n",
        "                        OR bib.issn = jor.issn_3\n",
        "                        OR bib.journal_name_key = jor.journal_name_key)\n",
        "                  AND bib.issn is not null \n",
        "                  AND bib.journal is not null;\"\"\")\n",
        "\n",
        "if config.export_format == 'xml':\n",
        "  df_final.pandas_api().to_pandas().to_xml(f\"{OUTPUT_FOLDER}/output.xml\")\n",
        "\n",
        "elif config.export_format == 'csv':\n",
        "  df_final.withColumn('abstract', F.regexp_replace('abstract', r\"([\\n\\t]+)\", \" \"))\\\n",
        "    .write.mode(\"overwrite\")\\\n",
        "    .csv(OUTPUT_FOLDER, sep='|', header=True, escapeQuotes=True, escape=\"\\\\\", charToEscapeQuoteEscaping=\"\\\\\", )\n",
        "\n",
        "elif config.export_format == 'json':\n",
        "  df_final.write.mode(\"overwrite\").json(OUTPUT_FOLDER)\n",
        "  df_final.pandas_api().to_pandas().to_json(f\"{OUTPUT_FOLDER}/output.json\", orient=\"records\")\n",
        "\n",
        "elif config.export_format == 'yaml':\n",
        "  yaml.dump(df_final.pandas_api().to_pandas().to_dict(orient='records'), open(f\"{OUTPUT_FOLDER}/output.yaml\", 'w'))"
      ],
      "metadata": {
        "id": "zZdTw5mBn61C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}